{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac854b72-f011-4b15-aa88-fbf75e13c731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  gender  nobet_tipi  nobet_frequnency  disease_duration  \\\n",
      "0   52       1           1                 0               3.0   \n",
      "1   19       1           1                 2               8.0   \n",
      "2   55       1           1                 0               0.4   \n",
      "3   29       1           1                 2              25.0   \n",
      "4   71       1           1                 2               6.0   \n",
      "\n",
      "   marital_status  se_history  nbt_uyku  nbt_uyaniklik  head_trauma  \\\n",
      "0               1           0         1              0            0   \n",
      "1               0           0         0              1            1   \n",
      "2               1           1         0              1            0   \n",
      "3               0           0         0              1            1   \n",
      "4               1           0         0              1            1   \n",
      "\n",
      "   interceptive_delivery  febril_convulsion  epilepsy_family_history  \\\n",
      "0                      0                  0                        0   \n",
      "1                      0                  0                        0   \n",
      "2                      0                  0                        0   \n",
      "3                      0                  0                        2   \n",
      "4                      0                  0                        0   \n",
      "\n",
      "   fk_fever_nbt_family  family_history  comorbid_diseases  \\\n",
      "0                    0               0                  0   \n",
      "1                    0               3                  0   \n",
      "2                    0               0                  1   \n",
      "3                    0               0                  1   \n",
      "4                    0               0                  1   \n",
      "\n",
      "                                          eeg_sonucu  \n",
      "0                                             normal  \n",
      "1  bu eeg bulgusu birkaç kez izlenen jeneralize d...  \n",
      "2  sol fronto temporal alanda keskin dalga disrit...  \n",
      "3   ılımlı zemin ritmi düzensizliğinin izlendiği eeg  \n",
      "4                                             normal  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593 entries, 0 to 592\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   age                      593 non-null    int64  \n",
      " 1   gender                   593 non-null    int64  \n",
      " 2   nobet_tipi               593 non-null    int64  \n",
      " 3   nobet_frequnency         593 non-null    int64  \n",
      " 4   disease_duration         593 non-null    float64\n",
      " 5   marital_status           593 non-null    int64  \n",
      " 6   se_history               593 non-null    int64  \n",
      " 7   nbt_uyku                 593 non-null    int64  \n",
      " 8   nbt_uyaniklik            593 non-null    int64  \n",
      " 9   head_trauma              593 non-null    int64  \n",
      " 10  interceptive_delivery    593 non-null    int64  \n",
      " 11  febril_convulsion        593 non-null    int64  \n",
      " 12  epilepsy_family_history  593 non-null    int64  \n",
      " 13  fk_fever_nbt_family      593 non-null    int64  \n",
      " 14  family_history           593 non-null    int64  \n",
      " 15  comorbid_diseases        593 non-null    int64  \n",
      " 16  eeg_sonucu               593 non-null    object \n",
      "dtypes: float64(1), int64(15), object(1)\n",
      "memory usage: 78.9+ KB\n",
      "None\n",
      "              age      gender  nobet_tipi  nobet_frequnency  disease_duration  \\\n",
      "count  593.000000  593.000000  593.000000        593.000000        593.000000   \n",
      "mean    33.264755    0.483980    0.962901          0.790894         13.204941   \n",
      "std     14.051031    0.500165    0.189165          0.848360         11.501271   \n",
      "min     17.000000    0.000000    0.000000          0.000000          0.010000   \n",
      "25%     22.000000    0.000000    1.000000          0.000000          4.000000   \n",
      "50%     29.000000    0.000000    1.000000          1.000000         10.000000   \n",
      "75%     42.000000    1.000000    1.000000          2.000000         20.000000   \n",
      "max     85.000000    1.000000    1.000000          2.000000         52.000000   \n",
      "\n",
      "       marital_status  se_history    nbt_uyku  nbt_uyaniklik  head_trauma  \\\n",
      "count      593.000000  593.000000  593.000000     593.000000   593.000000   \n",
      "mean         0.578415    0.082631    0.510961       0.858347     0.239460   \n",
      "std          0.740484    0.275556    0.500302       0.348988     0.427114   \n",
      "min          0.000000    0.000000    0.000000       0.000000     0.000000   \n",
      "25%          0.000000    0.000000    0.000000       1.000000     0.000000   \n",
      "50%          0.000000    0.000000    1.000000       1.000000     0.000000   \n",
      "75%          1.000000    0.000000    1.000000       1.000000     0.000000   \n",
      "max          4.000000    1.000000    1.000000       1.000000     1.000000   \n",
      "\n",
      "       interceptive_delivery  febril_convulsion  epilepsy_family_history  \\\n",
      "count             593.000000         593.000000               593.000000   \n",
      "mean                0.150084           0.222597                 0.610455   \n",
      "std                 0.357456           0.416341                 1.007585   \n",
      "min                 0.000000           0.000000                 0.000000   \n",
      "25%                 0.000000           0.000000                 0.000000   \n",
      "50%                 0.000000           0.000000                 0.000000   \n",
      "75%                 0.000000           0.000000                 1.000000   \n",
      "max                 1.000000           1.000000                 4.000000   \n",
      "\n",
      "       fk_fever_nbt_family  family_history  comorbid_diseases  \n",
      "count           593.000000      593.000000         593.000000  \n",
      "mean              0.141653        1.003373           0.411467  \n",
      "std               0.442851        1.510097           0.492515  \n",
      "min               0.000000        0.000000           0.000000  \n",
      "25%               0.000000        0.000000           0.000000  \n",
      "50%               0.000000        0.000000           0.000000  \n",
      "75%               0.000000        3.000000           1.000000  \n",
      "max               3.000000        4.000000           1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Veriyi yükleme\n",
    "file_path = './data.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Verinin genel yapısını inceleme\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92426c67-f9f3-4c78-8bf5-665e9fc5a29e",
   "metadata": {},
   "source": [
    "### Data processing, Vectorization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1a55db-78df-4831-8a72-586cabf123b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# TF-IDF vektörizasyonu\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(data['eeg_sonucu'])\n",
    "\n",
    "# PCA ile boyut indirgeme\n",
    "pca = PCA(n_components=1)\n",
    "eeg_numeric = pca.fit_transform(tfidf_matrix.toarray())\n",
    "\n",
    "# Yeni nümerik değeri veri setine ekleme\n",
    "data['eeg_numeric'] = eeg_numeric\n",
    "data = data.drop(columns=['eeg_sonucu'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cb606-f770-48de-bc75-eccecf5ca8eb",
   "metadata": {},
   "source": [
    "### SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4960a1af-6236-487b-90d9-382774df7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Input ve output ayrıştırma\n",
    "X = data.drop(columns=['nobet_tipi'])\n",
    "y = data['nobet_tipi']\n",
    "\n",
    "# SMOTE kullanarak veri artırma\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef75de-bffd-403e-ad8e-ec793ba86139",
   "metadata": {},
   "source": [
    "#### First MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfd6d61-d500-442e-a3ca-4684948e436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cevher/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6164752840995789\n",
      "Epoch 2/10, Loss: 0.5590840578079224\n",
      "Epoch 3/10, Loss: 0.5784189105033875\n",
      "Epoch 4/10, Loss: 0.24356107413768768\n",
      "Epoch 5/10, Loss: 0.5700127482414246\n",
      "Epoch 6/10, Loss: 0.2463884949684143\n",
      "Epoch 7/10, Loss: 0.24983526766300201\n",
      "Epoch 8/10, Loss: 0.20380906760692596\n",
      "Epoch 9/10, Loss: 0.1159171536564827\n",
      "Epoch 10/10, Loss: 0.1682053804397583\n",
      "F1 Score: 0.8908880017825423, Recall: 0.8908296943231441, Accuracy: 0.8908296943231441\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "\n",
    "# Veri setini PyTorch tensörlerine dönüştürme\n",
    "X_tensor = torch.tensor(X_resampled.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_resampled.values, dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# MLP modeli oluşturma\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_tensor.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = len(data['nobet_tipi'].unique())\n",
    "\n",
    "model = MLP(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Loss ve optimizer belirleme\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Modeli eğitme\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Modeli değerlendirme fonksiyonu\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return f1, recall, accuracy\n",
    "\n",
    "f1, recall, accuracy = evaluate_model(model, test_dataloader)\n",
    "print(f'F1 Score: {f1}, Recall: {recall}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dec273-1e11-4918-a63c-e3c015d532ed",
   "metadata": {},
   "source": [
    "### Second model with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab311bb2-4bf9-4d4b-b4d4-fcab24176c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-01 09:47:25,118] A new study created in memory with name: no-name-177309be-3620-433a-b816-d18ecc52d643\n",
      "[I 2024-08-01 09:47:25,845] Trial 0 finished with value: 0.9737721051104047 and parameters: {'hidden_dim': 137, 'hidden_layers': 2, 'dropout_rate': 0.48728865590840265, 'lr': 0.0033883196726438095}. Best is trial 0 with value: 0.9737721051104047.\n",
      "[I 2024-08-01 09:47:28,591] Trial 1 finished with value: 0.97814926432341 and parameters: {'hidden_dim': 377, 'hidden_layers': 5, 'dropout_rate': 0.25679902168633306, 'lr': 0.0006938671157206147}. Best is trial 1 with value: 0.97814926432341.\n",
      "[I 2024-08-01 09:47:29,139] Trial 2 finished with value: 0.9562868418506743 and parameters: {'hidden_dim': 171, 'hidden_layers': 2, 'dropout_rate': 0.3785001309084586, 'lr': 0.00017669580874701227}. Best is trial 1 with value: 0.97814926432341.\n",
      "[I 2024-08-01 09:47:30,201] Trial 3 finished with value: 0.9563285468274827 and parameters: {'hidden_dim': 181, 'hidden_layers': 5, 'dropout_rate': 0.13496098622754032, 'lr': 0.005925863602444748}. Best is trial 1 with value: 0.97814926432341.\n",
      "[I 2024-08-01 09:47:31,015] Trial 4 finished with value: 0.9300376536702494 and parameters: {'hidden_dim': 178, 'hidden_layers': 4, 'dropout_rate': 0.18404235473484123, 'lr': 0.0024551358511058245}. Best is trial 1 with value: 0.97814926432341.\n",
      "[I 2024-08-01 09:47:32,275] Trial 5 finished with value: 0.9562232754967968 and parameters: {'hidden_dim': 320, 'hidden_layers': 4, 'dropout_rate': 0.23003884180303094, 'lr': 0.006020287550745545}. Best is trial 1 with value: 0.97814926432341.\n",
      "[I 2024-08-01 09:47:33,001] Trial 6 finished with value: 0.9475442102208093 and parameters: {'hidden_dim': 107, 'hidden_layers': 4, 'dropout_rate': 0.32367446211107376, 'lr': 0.009773970658294573}. Best is trial 1 with value: 0.97814926432341.\n",
      "[I 2024-08-01 09:47:34,921] Trial 7 finished with value: 0.9781642729372174 and parameters: {'hidden_dim': 374, 'hidden_layers': 5, 'dropout_rate': 0.33765689741940663, 'lr': 0.004879716809141991}. Best is trial 7 with value: 0.9781642729372174.\n",
      "[I 2024-08-01 09:47:35,288] Trial 8 finished with value: 0.9650588373295798 and parameters: {'hidden_dim': 109, 'hidden_layers': 1, 'dropout_rate': 0.2610429532680954, 'lr': 0.008630891377001309}. Best is trial 7 with value: 0.9781642729372174.\n",
      "[I 2024-08-01 09:47:35,655] Trial 9 finished with value: 0.9650294734805395 and parameters: {'hidden_dim': 171, 'hidden_layers': 1, 'dropout_rate': 0.2689493023739048, 'lr': 0.00701776336567318}. Best is trial 7 with value: 0.9781642729372174.\n",
      "[I 2024-08-01 09:47:37,363] Trial 10 finished with value: 0.9606461290250724 and parameters: {'hidden_dim': 499, 'hidden_layers': 3, 'dropout_rate': 0.41545544968816145, 'lr': 0.0040129971061577605}. Best is trial 7 with value: 0.9781642729372174.\n",
      "[I 2024-08-01 09:47:39,254] Trial 11 finished with value: 0.95186586721307 and parameters: {'hidden_dim': 382, 'hidden_layers': 5, 'dropout_rate': 0.34167477756471787, 'lr': 7.71757196212728e-05}. Best is trial 7 with value: 0.9781642729372174.\n",
      "[I 2024-08-01 09:47:41,345] Trial 12 finished with value: 0.9562584298171815 and parameters: {'hidden_dim': 411, 'hidden_layers': 5, 'dropout_rate': 0.19337200762820567, 'lr': 0.0020389627451511305}. Best is trial 7 with value: 0.9781642729372174.\n",
      "[I 2024-08-01 09:47:42,833] Trial 13 finished with value: 0.9825294186647899 and parameters: {'hidden_dim': 289, 'hidden_layers': 5, 'dropout_rate': 0.45289865164618615, 'lr': 0.001781886623652632}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:44,213] Trial 14 finished with value: 0.9650468320440936 and parameters: {'hidden_dim': 288, 'hidden_layers': 4, 'dropout_rate': 0.4943858040258302, 'lr': 0.004417039049463983}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:45,033] Trial 15 finished with value: 0.9650468320440936 and parameters: {'hidden_dim': 256, 'hidden_layers': 3, 'dropout_rate': 0.43337788345214295, 'lr': 0.002002111779884374}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:47,929] Trial 16 finished with value: 0.9125470670878116 and parameters: {'hidden_dim': 466, 'hidden_layers': 5, 'dropout_rate': 0.4321033550776861, 'lr': 0.005434044382827185}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:49,185] Trial 17 finished with value: 0.9563235466619746 and parameters: {'hidden_dim': 255, 'hidden_layers': 4, 'dropout_rate': 0.38571192886883904, 'lr': 0.0077283764207022165}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:50,211] Trial 18 finished with value: 0.9650294734805395 and parameters: {'hidden_dim': 329, 'hidden_layers': 3, 'dropout_rate': 0.34910735120907993, 'lr': 0.00303374876926235}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:52,551] Trial 19 finished with value: 0.9650294734805395 and parameters: {'hidden_dim': 434, 'hidden_layers': 5, 'dropout_rate': 0.4582846095066855, 'lr': 0.0012697673758095425}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:53,325] Trial 20 finished with value: 0.9562868418506743 and parameters: {'hidden_dim': 341, 'hidden_layers': 2, 'dropout_rate': 0.3081586378765093, 'lr': 0.0047061264674497375}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:55,190] Trial 21 finished with value: 0.9519559049982457 and parameters: {'hidden_dim': 379, 'hidden_layers': 5, 'dropout_rate': 0.2697057140997727, 'lr': 0.0012466808842858134}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:56,478] Trial 22 finished with value: 0.9650588373295798 and parameters: {'hidden_dim': 253, 'hidden_layers': 5, 'dropout_rate': 0.2176069121058183, 'lr': 0.0009291226025744514}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:58,077] Trial 23 finished with value: 0.9562232754967968 and parameters: {'hidden_dim': 363, 'hidden_layers': 4, 'dropout_rate': 0.37559134304907366, 'lr': 0.0033106254735873484}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:47:59,556] Trial 24 finished with value: 0.9781642729372174 and parameters: {'hidden_dim': 287, 'hidden_layers': 5, 'dropout_rate': 0.15457795584577705, 'lr': 0.0010357554958964467}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:00,777] Trial 25 finished with value: 0.9475442102208093 and parameters: {'hidden_dim': 290, 'hidden_layers': 4, 'dropout_rate': 0.1016387030325901, 'lr': 0.0018610060327090272}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:01,916] Trial 26 finished with value: 0.969421815062315 and parameters: {'hidden_dim': 209, 'hidden_layers': 5, 'dropout_rate': 0.17076398330153442, 'lr': 0.002500328377553029}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:03,268] Trial 27 finished with value: 0.969421815062315 and parameters: {'hidden_dim': 294, 'hidden_layers': 4, 'dropout_rate': 0.14502567014073342, 'lr': 0.0040280284016993295}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:04,544] Trial 28 finished with value: 0.9693914336861672 and parameters: {'hidden_dim': 235, 'hidden_layers': 5, 'dropout_rate': 0.29346623855543985, 'lr': 0.005189356808053121}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:06,036] Trial 29 finished with value: 0.9563318777292577 and parameters: {'hidden_dim': 436, 'hidden_layers': 3, 'dropout_rate': 0.4638223987833838, 'lr': 0.006908721788011276}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:06,743] Trial 30 finished with value: 0.969421815062315 and parameters: {'hidden_dim': 64, 'hidden_layers': 5, 'dropout_rate': 0.399233840077197, 'lr': 0.002870903546945914}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:08,477] Trial 31 finished with value: 0.9650294734805395 and parameters: {'hidden_dim': 352, 'hidden_layers': 5, 'dropout_rate': 0.23509950784022193, 'lr': 0.000801172353307112}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:10,931] Trial 32 finished with value: 0.9562232754967968 and parameters: {'hidden_dim': 409, 'hidden_layers': 5, 'dropout_rate': 0.35400371425759386, 'lr': 0.0006662865716273312}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:12,480] Trial 33 finished with value: 0.9650067438537453 and parameters: {'hidden_dim': 306, 'hidden_layers': 5, 'dropout_rate': 0.10811011675705395, 'lr': 0.001433166100341394}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:13,406] Trial 34 finished with value: 0.9650588373295798 and parameters: {'hidden_dim': 211, 'hidden_layers': 4, 'dropout_rate': 0.15292277405158478, 'lr': 0.0003988080573610991}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:15,552] Trial 35 finished with value: 0.9301256749239721 and parameters: {'hidden_dim': 391, 'hidden_layers': 5, 'dropout_rate': 0.2116833744518371, 'lr': 0.0017064728550374286}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:16,931] Trial 36 finished with value: 0.9737851240330704 and parameters: {'hidden_dim': 327, 'hidden_layers': 4, 'dropout_rate': 0.29679429093240295, 'lr': 0.0036496656264113575}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:17,576] Trial 37 finished with value: 0.9213823839915543 and parameters: {'hidden_dim': 268, 'hidden_layers': 2, 'dropout_rate': 0.2569395373148306, 'lr': 5.317920616121092e-05}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:19,004] Trial 38 finished with value: 0.9606851907944047 and parameters: {'hidden_dim': 352, 'hidden_layers': 4, 'dropout_rate': 0.4709117137907831, 'lr': 0.002509369467034855}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:20,671] Trial 39 finished with value: 0.9519614004618783 and parameters: {'hidden_dim': 315, 'hidden_layers': 5, 'dropout_rate': 0.12328232072049403, 'lr': 0.0058272866499569495}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:21,915] Trial 40 finished with value: 0.9474176129654247 and parameters: {'hidden_dim': 214, 'hidden_layers': 5, 'dropout_rate': 0.3247204704831114, 'lr': 0.008368335475391998}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:23,984] Trial 41 finished with value: 0.9737851240330704 and parameters: {'hidden_dim': 328, 'hidden_layers': 4, 'dropout_rate': 0.24638148510955094, 'lr': 0.0041528729273642385}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:27,574] Trial 42 finished with value: 0.921337396228226 and parameters: {'hidden_dim': 368, 'hidden_layers': 5, 'dropout_rate': 0.2890231142451584, 'lr': 0.0036003367715918607}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:30,553] Trial 43 finished with value: 0.9562868418506743 and parameters: {'hidden_dim': 401, 'hidden_layers': 4, 'dropout_rate': 0.31433096639241465, 'lr': 0.003397158123640079}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:33,336] Trial 44 finished with value: 0.9650668345441161 and parameters: {'hidden_dim': 276, 'hidden_layers': 5, 'dropout_rate': 0.2802369995196585, 'lr': 0.006445642952565237}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:35,300] Trial 45 finished with value: 0.9650067438537453 and parameters: {'hidden_dim': 438, 'hidden_layers': 3, 'dropout_rate': 0.1864264432271244, 'lr': 0.002317598021638257}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:37,098] Trial 46 finished with value: 0.9430051718085599 and parameters: {'hidden_dim': 308, 'hidden_layers': 4, 'dropout_rate': 0.370296989545546, 'lr': 0.004883271933737719}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:38,152] Trial 47 finished with value: 0.9606461290250724 and parameters: {'hidden_dim': 144, 'hidden_layers': 5, 'dropout_rate': 0.21468354385082644, 'lr': 0.0005669441596947624}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:40,740] Trial 48 finished with value: 0.9606175277197845 and parameters: {'hidden_dim': 498, 'hidden_layers': 4, 'dropout_rate': 0.3305040097431199, 'lr': 0.0015362451009285191}. Best is trial 13 with value: 0.9825294186647899.\n",
      "[I 2024-08-01 09:48:42,449] Trial 49 finished with value: 0.9737721051104047 and parameters: {'hidden_dim': 339, 'hidden_layers': 5, 'dropout_rate': 0.4207063662153676, 'lr': 0.001024446715777424}. Best is trial 13 with value: 0.9825294186647899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "F1 Score: 0.9825294186647899\n",
      "Best hyperparameters:  {'hidden_dim': 289, 'hidden_layers': 5, 'dropout_rate': 0.45289865164618615, 'lr': 0.001781886623652632}\n",
      "Epoch 1/20, Loss: 0.4646921455860138\n",
      "Epoch 2/20, Loss: 0.13262349367141724\n",
      "Epoch 3/20, Loss: 0.2951509952545166\n",
      "Epoch 4/20, Loss: 0.3275938034057617\n",
      "Epoch 5/20, Loss: 0.2633124887943268\n",
      "Epoch 6/20, Loss: 0.3078048527240753\n",
      "Epoch 7/20, Loss: 0.15478119254112244\n",
      "Epoch 8/20, Loss: 0.10209742933511734\n",
      "Epoch 9/20, Loss: 0.03725193440914154\n",
      "Epoch 10/20, Loss: 0.11200488358736038\n",
      "Epoch 11/20, Loss: 0.07284894585609436\n",
      "Epoch 12/20, Loss: 0.10156287252902985\n",
      "Epoch 13/20, Loss: 0.1469414234161377\n",
      "Epoch 14/20, Loss: 0.05503818392753601\n",
      "Epoch 15/20, Loss: 0.06185167655348778\n",
      "Epoch 16/20, Loss: 0.054849348962306976\n",
      "Epoch 17/20, Loss: 0.15650558471679688\n",
      "Epoch 18/20, Loss: 0.03896467387676239\n",
      "Epoch 19/20, Loss: 0.06823410838842392\n",
      "Epoch 20/20, Loss: 0.028532199561595917\n",
      "F1 Score: 0.9693914336861672, Recall: 0.9694323144104804, Accuracy: 0.9694323144104804\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "\n",
    "# MLP modeli\n",
    "class DeepMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_layers, output_dim, dropout_rate):\n",
    "        super(DeepMLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Optuna ile hiperparametre optimizasyonu\n",
    "def objective(trial):\n",
    "    input_dim = X_tensor.shape[1]\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 512)\n",
    "    hidden_layers = trial.suggest_int('hidden_layers', 1, 5)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2)\n",
    "\n",
    "    model = DeepMLP(input_dim, hidden_dim, hidden_layers, output_dim, dropout_rate)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    f1, recall, accuracy = evaluate_model(model, test_dataloader)\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'F1 Score: {trial.value}')\n",
    "print('Best hyperparameters: ', trial.params)\n",
    "\n",
    "# En iyi hiperparametrelerle model eğitme\n",
    "best_params = trial.params\n",
    "model = DeepMLP(input_dim, best_params['hidden_dim'], best_params['hidden_layers'], output_dim, best_params['dropout_rate'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params['lr'])\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "f1, recall, accuracy = evaluate_model(model, test_dataloader)\n",
    "print(f'F1 Score: {f1}, Recall: {recall}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf0139f-7f74-4afb-b71d-209b416a6eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9738580278257338, Recall: 0.9737991266375546, Accuracy: 0.9737991266375546\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Geliştirilmiş MLP modeli (baz model)\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_layers, output_dim, dropout_rate):\n",
    "        super(ImprovedMLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Temel modelleri eğitme\n",
    "input_dim = X_tensor.shape[1]\n",
    "hidden_dim = best_params['hidden_dim']\n",
    "hidden_layers = best_params['hidden_layers']\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "lr = best_params['lr']\n",
    "output_dim = len(data['nobet_tipi'].unique())\n",
    "\n",
    "def train_mlp_model(X_train, y_train, X_val, y_val):\n",
    "    model = ImprovedMLP(input_dim, hidden_dim, hidden_layers, output_dim, dropout_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 20\n",
    "    best_model = None\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in DataLoader(TensorDataset(X_val, y_val), batch_size=32, shuffle=False):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(X_val)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n",
    "\n",
    "# Veriyi eğitim ve doğrulama setlerine ayırma\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Baz modelleri eğitme\n",
    "mlp_model = train_mlp_model(X_train, y_train, X_val, y_val)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train_val.numpy(), y_train_val.numpy())\n",
    "svm_model = SVC(probability=True, random_state=42).fit(X_train_val.numpy(), y_train_val.numpy())\n",
    "\n",
    "# Tahminleri meta model için hazırlama\n",
    "def get_predictions(models, X):\n",
    "    mlp_model, rf_model, svm_model = models\n",
    "    mlp_model.eval()\n",
    "    with torch.no_grad():\n",
    "        mlp_preds = mlp_model(X).numpy()\n",
    "    rf_preds = rf_model.predict_proba(X.numpy())\n",
    "    svm_preds = svm_model.predict_proba(X.numpy())\n",
    "    return np.hstack([mlp_preds, rf_preds, svm_preds])\n",
    "\n",
    "meta_train_preds = get_predictions([mlp_model, rf_model, svm_model], X_train_val)\n",
    "meta_test_preds = get_predictions([mlp_model, rf_model, svm_model], X_test)\n",
    "\n",
    "# Meta model eğitme\n",
    "meta_model = LogisticRegression(random_state=42)\n",
    "meta_model.fit(meta_train_preds, y_train_val.numpy())\n",
    "\n",
    "# Meta model ile tahmin yapma\n",
    "meta_preds = meta_model.predict(meta_test_preds)\n",
    "\n",
    "# Performans ölçütleri\n",
    "f1 = f1_score(y_test.numpy(), meta_preds, average='weighted')\n",
    "recall = recall_score(y_test.numpy(), meta_preds, average='weighted')\n",
    "accuracy = accuracy_score(y_test.numpy(), meta_preds)\n",
    "\n",
    "print(f'F1 Score: {f1}, Recall: {recall}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f0c33-c399-4c7e-8485-8ba66eb91c81",
   "metadata": {},
   "source": [
    "### Thirs Model with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0137cdc-0f27-415a-8308-439ed98fd22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cevher/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9825537877939624, Recall: 0.982532751091703, Accuracy: 0.982532751091703\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Geliştirilmiş MLP modeli (baz model)\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_layers, output_dim, dropout_rate):\n",
    "        super(ImprovedMLP, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Temel modelleri eğitme\n",
    "input_dim = X_tensor.shape[1]\n",
    "hidden_dim = best_params['hidden_dim']\n",
    "hidden_layers = best_params['hidden_layers']\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "lr = best_params['lr']\n",
    "output_dim = len(data['nobet_tipi'].unique())\n",
    "\n",
    "def train_mlp_model(X_train, y_train, X_val, y_val):\n",
    "    model = ImprovedMLP(input_dim, hidden_dim, hidden_layers, output_dim, dropout_rate)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_epochs = 20\n",
    "    best_model = None\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in DataLoader(TensorDataset(X_val, y_val), batch_size=32, shuffle=False):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(X_val)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n",
    "\n",
    "# Veriyi eğitim ve doğrulama setlerine ayırma\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "# Baz modelleri eğitme\n",
    "mlp_model = train_mlp_model(X_train, y_train, X_val, y_val)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42).fit(X_train_val.numpy(), y_train_val.numpy())\n",
    "svm_model = SVC(probability=True, random_state=42).fit(X_train_val.numpy(), y_train_val.numpy())\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5).fit(X_train_val.numpy(), y_train_val.numpy())\n",
    "\n",
    "# Tahminleri meta model için hazırlama\n",
    "def get_predictions(models, X):\n",
    "    mlp_model, rf_model, svm_model, knn_model = models\n",
    "    mlp_model.eval()\n",
    "    with torch.no_grad():\n",
    "        mlp_preds = mlp_model(X).numpy()\n",
    "    rf_preds = rf_model.predict_proba(X.numpy())\n",
    "    svm_preds = svm_model.predict_proba(X.numpy())\n",
    "    knn_preds = knn_model.predict_proba(X.numpy())\n",
    "    return np.hstack([mlp_preds, rf_preds, svm_preds, knn_preds])\n",
    "\n",
    "meta_train_preds = get_predictions([mlp_model, rf_model, svm_model, knn_model], X_train_val)\n",
    "meta_test_preds = get_predictions([mlp_model, rf_model, svm_model, knn_model], X_test)\n",
    "\n",
    "# Meta model eğitme\n",
    "meta_model = xgb.XGBClassifier(random_state=42)\n",
    "meta_model.fit(meta_train_preds, y_train_val.numpy())\n",
    "\n",
    "# Meta model ile tahmin yapma\n",
    "meta_preds = meta_model.predict(meta_test_preds)\n",
    "\n",
    "# Performans ölçütleri\n",
    "f1 = f1_score(y_test.numpy(), meta_preds, average='weighted')\n",
    "recall = recall_score(y_test.numpy(), meta_preds, average='weighted')\n",
    "accuracy = accuracy_score(y_test.numpy(), meta_preds)\n",
    "\n",
    "print(f'F1 Score: {f1}, Recall: {recall}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4417a56-e4bd-4710-8268-8225a60134bf",
   "metadata": {},
   "source": [
    "### Anyone who might use this repository should cite the work ©  \n",
    "### All rights belong to the writers (Dr. Cevher ÖZDEN and Dr. Pınar Bengi BOZ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
